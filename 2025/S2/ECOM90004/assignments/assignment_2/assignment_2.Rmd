---
title: "ECOM90004 Assignment 2 - code appendix"
output: html_document
author: "Josh Copeland (SID: 1444772)"
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}

library(tidyverse)
library(lubridate)
library(forecast)
library(urca)
library(car)

theme_set(theme_minimal())

```

```{r setup_comment}

#Packages used:

# library(tidyverse)
# library(lubridate)
# library(forecast)
# library(urca)
#library(car)

```

# Question 1

# (a) - (c)

```{r q1a_to_q1c}

# Question 1

# For code efficiency, answers to Q1a-Q1c are all given together below

# Data import and cleaning

data <- read_csv("USRealGDPPerCapita.csv") %>% 
  select(date = observation_date, value = RealGDPPerCap) %>% 
  mutate(date = dmy(date)) %>% 
  mutate(value = log(value)) %>% 
  na.omit() %>%
  # Variables for models
  mutate(time = row_number()*0.25) %>% 
  mutate(du_1 = if_else(lubridate::year(date) > 1973, 1, 0), dt_1 = if_else(year(date) > 1973, time, 0)) %>% 
  mutate(du_2 = if_else(lubridate::year(date) > 2008, 1, 0), dt_2 = if_else(year(date) > 2008, time, 0))

# Creating models

linear_model <- lm(value ~ time, data = data)
one_break_model <- lm(value ~ time + du_1 + dt_1, data = data)
two_break_model <- lm(value ~ time + du_1 + dt_1 + du_2 + dt_2, data = data)

# Creating table of coefficients

tab <- cbind(
  "Linear model (a)"  = coef(linear_model)[c("(Intercept)","time","du_1","dt_1","du_2","dt_2")],
  "1 break model (b)" = coef(one_break_model)[c("(Intercept)","time","du_1","dt_1","du_2","dt_2")],
  "2 break model (c)" = coef(two_break_model)[c("(Intercept)","time","du_1","dt_1","du_2","dt_2")]
)

rownames(tab) <- c("beta_0","beta_1", "beta_3","beta_4","beta_5","beta_6")
round(tab, 4)

# Creating charts of fitted values and residuals

models <- list(linear_model, one_break_model, two_break_model)
labs <- c("Linear model", "One-break model", "Two-break model")

invisible(lapply(seq_along(models), function(i){
  m <- models[[i]]; lab <- labs[i]
  aug <- data.frame(date = data$date, value = data$value, fitted = fitted(m), residuals = resid(m))
  p1 <- ggplot(aug, aes(date, value)) + geom_line() + geom_line(aes(y = fitted), color = "red", linewidth = 1) +
        labs(title = paste0("Chart ", (i-1)*2+1, ": ", lab, " \n fitted values"), x = "date", y = "value")
  p2 <- ggplot(aug, aes(date, residuals)) + geom_line() + geom_hline(yintercept = 0, linetype = "dashed") +
        labs(title = paste0("Chart ", (i-1)*2+2, ": ", lab, " \n residuals"), x = "date", y = "residuals")
  ggsave(paste0("chart", (i-1)*2+1, ".png"), p1, width = 3, height = 2.5, units = "in", dpi = 300)
  ggsave(paste0("chart", (i-1)*2+2, ".png"), p2, width = 3, height = 2.5, units = "in", dpi = 300)
}))

```

## (d) WRITTEN ANSWERS ONLY EXCEPT FOR III

### (iii)


```{r q1diii}

# We see if Perron's imposition of continuity is supported at 1973 and 2008 by applying a linear hypothesis test to see if the implied jump in the fitted value at each breakpoint is significantly different from zero.

# H0: no jump at 1973
linearHypothesis(two_break_model, "du_1 + 1973*dt_1 = 0")

# H0: no jump at 2008
linearHypothesis(two_break_model, "du_2 + 2008*dt_2 = 0")

```


# Question 2

### (a)

```{r q2a}


# function: fit AR(p) to residuals (Z), compute AICc & Ljungâ€“Box, mark min AICc
resid_ar_table <- function(model, label, pmax = 9) {
  Z <- resid(model); AICc <- LBp <- numeric(pmax + 1)          # storage
  for (p in 0:pmax) {                                          # loop over AR orders
    eq <- Arima(Z, order = c(p, 0, 0), include.mean = FALSE, method = "ML")
    AICc[p + 1] <- eq$aicc                                    # record AICc
    LBp[p + 1] <- Box.test(residuals(eq), lag = p + 4, 
                           type = "Ljung-Box", fitdf = p)$p.value
  }
  # results table for display
  Stats <- cbind(sprintf("%.4f", LBp),
                 sprintf("%.2f", AICc),
                 replace(rep("", pmax + 1), which.min(AICc), "<="))
  rownames(Stats) <- paste0("p=", 0:pmax); colnames(Stats) <- c("LBp", "AICc", "minAICc")
  cat("\n", label, "\n", sep = ""); print(Stats, quote = FALSE)

  # return summary row for this model
  data.frame(model = label, p = which.min(AICc) - 1,
             AICc = min(AICc), LB_p = LBp[which.min(AICc)])
}

# Run for all models 
models <- list(linear_model, one_break_model, two_break_model)    # model objects
names(models) <- c("linear_model", "one_break_model", "two_break_model")  # add labels

# combine results into final dataframe
final <- do.call(rbind, Map(function(m, lab) resid_ar_table(m, lab, pmax = 9),
                            models, names(models)))
print(final)

```


### (b) 

```{r q2b}

# models, labels, and max lags (linear=4, others=5)
models <- list(linear_model, one_break_model, two_break_model)
labels <- c("linear_model","one_break_model","two_break_model")
lags   <- c(5,4,4)

# compact ADF on residuals -> selected lag, t-stat, p-value (via punitroot)
adf_rows <- t(mapply(function(m, L) {
  adf  <- ur.df(resid(m), type="drift", selectlags="AIC", lags=L)
  tval <- as.numeric(adf@teststat[1])                # tau2 for 'drift'
  pval <- urca::punitroot(tval, trend="c", statistic="t")
  c(lag = adf@lags, t_stat = tval, p_value = pval)
}, models, lags, SIMPLIFY = TRUE))

adf_results <- data.frame(model = labels, adf_rows, row.names = NULL)
print(adf_results)

```


## (c)

```{r q2c}

# Sample sizes of residuals
n_vec <- sapply(models, function(m) length(resid(m)))

# Simulate null distributions and store 5% critical values
reps <- 1000
tstats_list <- vector("list", length(models))
cv5 <- numeric(length(models))
for(i in seq_along(models)){
  tstats <- replicate(reps, {
    y <- cumsum(rnorm(n_vec[i]))                                # random walk under H0
    as.numeric(ur.df(y, type="drift", selectlags="AIC", lags=lags[i])@teststat[1])  # tau2
  })
  tstats_list[[i]] <- tstats
  cv5[i] <- unname(quantile(tstats, 0.05, na.rm = TRUE))        # 5% critical value
}

cv_table <- data.frame(model = labels, Lmax = lags, cv_5pct = cv5)
print(cv_table)

```

## (d)

```{r q2d}

# Observed ADF t statistics on residuals (drift, AIC, same lag caps)
obs_t <- numeric(length(models))
for(i in seq_along(models)){
  adf <- ur.df(resid(models[[i]]), type="drift", selectlags="AIC", lags=lags[i])
  obs_t[i] <- as.numeric(adf@teststat[1])
}

# Simulated p-values using the saved null draws in tstats_list
pvals <- numeric(length(models))
for(i in seq_along(models)){
  tsim <- tstats_list[[i]]
  pvals[i] <- mean(tsim <= obs_t[i])   # left-tail probability under H0
}

# Table of simulated p-values
p_table <- data.frame(model = labels, t_stat = obs_t, p_sim = pvals)
print(p_table)

```


## (e)  WRITTEN ANSWERS ONLY

## (f) WRITTEN ANSWERS ONLY


